{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162a9ed1-c104-4572-9b0a-cdb39f628aeb",
   "metadata": {},
   "source": [
    "# Automatic predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ade2873-f23f-4b3b-a55b-d804f5160249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e9448-5577-43dc-9f50-579f3f4c68de",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c440fdd-6f97-4f42-ba6f-66435ca539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCorrelationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, summaries, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        summary = self.summaries[idx]\n",
    "        label = self.labels[idx]\n",
    "        text_encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        summary_encoding = self.tokenizer(summary, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        encoding = self.tokenizer(text, summary, truncation='only_first')\n",
    "        ans = {\n",
    "            # 'text_input_ids': text_encoding['input_ids'].flatten(), \n",
    "            # 'text_attention_mask': text_encoding['attention_mask'].flatten(), \n",
    "            # 'summary_input_ids': summary_encoding['input_ids'].flatten(),\n",
    "            # 'summary_attention_mask': summary_encoding['attention_mask'].flatten(),\n",
    "            'input_ids': encoding['input_ids'],\n",
    "            'attention_mask': encoding['attention_mask'],\n",
    "            'label': torch.tensor(label),\n",
    "            # 'labels': torch.tensor(label)\n",
    "        }\n",
    "        \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a09c3-b111-4e8c-b088-5f296146c7d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeca26-3b97-4488-a235-ace05d744f84",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c515ea08-0d92-4dd6-984b-024aa6add0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mbart_predictions': <class 'str'>, 'mbart_predictions_Актуальность': 'Float64', 'mbart_predictions_Последовательность': 'Float64', 'mbart_predictions_Беглость': 'Float64', 'mbart_predictions_Согласованность': 'Float64', 'mbart_predictions_Комментарий': <class 'str'>, 'mt5_predictions': <class 'str'>, 'mt5_predictions_Актуальность': 'Float64', 'mt5_predictions_Последовательность': 'Float64', 'mt5_predictions_Беглость': 'Float64', 'mt5_predictions_Согласованность': 'Float64', 'mt5_predictions_Комментарий': <class 'str'>, 'summarunner_predictions': <class 'str'>, 'summarunner_predictions_Актуальность': 'Float64', 'summarunner_predictions_Последовательность': 'Float64', 'summarunner_predictions_Беглость': 'Float64', 'summarunner_predictions_Согласованность': 'Float64', 'summarunner_predictions_Комментарий': <class 'str'>, 'llama_7b_predictions': <class 'str'>, 'llama_7b_predictions_Актуальность': 'Float64', 'llama_7b_predictions_Последовательность': 'Float64', 'llama_7b_predictions_Беглость': 'Float64', 'llama_7b_predictions_Согласованность': 'Float64', 'llama_7b_predictions_Комментарий': <class 'str'>, 'starling_predictions': <class 'str'>, 'starling_predictions_Актуальность': 'Float64', 'starling_predictions_Последовательность': 'Float64', 'starling_predictions_Беглость': 'Float64', 'starling_predictions_Согласованность': 'Float64', 'starling_predictions_Комментарий': <class 'str'>, 'yagpt_predictions': <class 'str'>, 'yagpt_predictions_Актуальность': 'Float64', 'yagpt_predictions_Последовательность': 'Float64', 'yagpt_predictions_Беглость': 'Float64', 'yagpt_predictions_Согласованность': 'Float64', 'yagpt_predictions_Комментарий': <class 'str'>, 'yagpt3_predictions': <class 'str'>, 'yagpt3_predictions_Актуальность': 'Float64', 'yagpt3_predictions_Последовательность': 'Float64', 'yagpt3_predictions_Беглость': 'Float64', 'yagpt3_predictions_Согласованность': 'Float64', 'yagpt3_predictions_Комментарий': <class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "index = \"Ind\"\n",
    "title = \"title\"\n",
    "article = \"text\"\n",
    "ground_truth = \"summary\"\n",
    "\n",
    "files = [\n",
    "    \"mbart_predictions.txt\",\n",
    "    \"mt5_predictions.txt\",\n",
    "    \"summarunner_predictions.txt\",\n",
    "    \"llama_7b_predictions.csv\",\n",
    "    \"starling_predictions.csv\",\n",
    "    \"yagpt_predictions.csv\",\n",
    "    \"yagpt3_predictions.csv\"\n",
    "]\n",
    "summaries_fields = []\n",
    "human_metrics = [\n",
    "    \"Актуальность\",\n",
    "    \"Последовательность\",\n",
    "    \"Беглость\",\n",
    "    \"Согласованность\",\n",
    "    \"Комментарий\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    model_name = file.split(\".\")[0]\n",
    "    summaries_fields.append(model_name)\n",
    "    for metric in human_metrics:\n",
    "        summaries_fields.append(f\"{model_name}_{metric}\")\n",
    "\n",
    "summaries_fields_types = {field : ('Float64' if field.split(\"_\")[-1] != human_metrics[-1] and field + \".txt\" not in files and field + \".csv\" not in files else str) for field in summaries_fields}\n",
    "print(summaries_fields_types)\n",
    "summaries_fields_types[index] = 'Int64'\n",
    "summaries_fields_types[article] = summaries_fields_types[ground_truth] = str\n",
    "\n",
    "metrics_data = pd.read_csv(\"metrics_data.csv\", dtype=summaries_fields_types)\n",
    "expert_data = pd.read_csv(\"compiled_expert_data.csv\", dtype=summaries_fields_types)\n",
    "# data = pd.read_csv(\"export_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cdf2cd-1115-410f-b95b-7173a1076df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>mbart_predictions</th>\n",
       "      <th>mt5_predictions</th>\n",
       "      <th>summarunner_predictions</th>\n",
       "      <th>llama_7b_predictions</th>\n",
       "      <th>starling_predictions</th>\n",
       "      <th>yagpt_predictions</th>\n",
       "      <th>yagpt3_predictions</th>\n",
       "      <th>...</th>\n",
       "      <th>mbart_predictions_meteor</th>\n",
       "      <th>mt5_predictions_meteor</th>\n",
       "      <th>summarunner_predictions_meteor</th>\n",
       "      <th>llama_7b_predictions_meteor</th>\n",
       "      <th>starling_predictions_meteor</th>\n",
       "      <th>yagpt_predictions_meteor</th>\n",
       "      <th>yagpt3_predictions_meteor</th>\n",
       "      <th>mbart_predictions_bleu.1</th>\n",
       "      <th>mt5_predictions_bleu.1</th>\n",
       "      <th>summarunner_predictions_bleu.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Названа опасность постоянно включенного Blueto...</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Активированный в смартфоне Bluetooth может пре...</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Эксперты предупреждают о том, что отключать Bl...</td>\n",
       "      <td>постоянно включенный bluetooth на смартфоне гр...</td>\n",
       "      <td>Bluetooth постоянно включен, это опасно, так к...</td>\n",
       "      <td>Постоянно включенный Bluetooth может создавать...</td>\n",
       "      <td>- Постоянно включенный Bluetooth на смартфоне ...</td>\n",
       "      <td>Доцент кафедры информатики РЭУ им. Плеханова А...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126459</td>\n",
       "      <td>0.053648</td>\n",
       "      <td>0.168245</td>\n",
       "      <td>0.207257</td>\n",
       "      <td>0.127202</td>\n",
       "      <td>0.168304</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Колесникова проходит подозреваемой по делу о з...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Члена президиума оппозиционного Координационно...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>член президиума координационного совета оппози...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>- Член президиума координационного совета оппо...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248829</td>\n",
       "      <td>0.101734</td>\n",
       "      <td>0.263807</td>\n",
       "      <td>0.231588</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.327753</td>\n",
       "      <td>0.224195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutsche Bank: в мире наступает эпоха беспорядка</td>\n",
       "      <td>Аналитики Deutsche Bank обнародовали исследова...</td>\n",
       "      <td>В истории человечества наступает эпоха беспоря...</td>\n",
       "      <td>В 2020 году в мире наступит новая эпоха беспор...</td>\n",
       "      <td>Пандемия коронавируса привела к появлениям нов...</td>\n",
       "      <td>аналитики deutsche bank обнародовали исследова...</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>Аналитики Deutsche Bank предполагают, что 2020...</td>\n",
       "      <td>- Аналитики Deutsche Bank предсказали наступле...</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309631</td>\n",
       "      <td>0.086664</td>\n",
       "      <td>0.314012</td>\n",
       "      <td>0.262029</td>\n",
       "      <td>0.238650</td>\n",
       "      <td>0.295642</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Ъ»: Минтранс подготовил проект поправок к ПДД</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>Масштабный проект изменений в ПДД подготовили ...</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>В Госдуму вступили в силу поправки в правила д...</td>\n",
       "      <td>гибдд совместно с минтрансом разработала масшт...</td>\n",
       "      <td>ГИБДД и Минтранс разработали проект изменений ...</td>\n",
       "      <td>ГИБДД и Минтранс разработали проект изменений ...</td>\n",
       "      <td>- ГИБДД и Минтранс разработали масштабный прое...</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработали масшт...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306315</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.233184</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.270406</td>\n",
       "      <td>0.338463</td>\n",
       "      <td>0.296722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesla выпустит бюджетный беспилотник в 2023 году</td>\n",
       "      <td>Вечером 22 сентября на конференции Battery Day...</td>\n",
       "      <td>Миллиардер Илон Маск пообещал представить бюдж...</td>\n",
       "      <td>На конференции Battery Day глава Tesla Илон Ма...</td>\n",
       "      <td>Илон Маск рассчитывает вывести на рынок бюджет...</td>\n",
       "      <td>вечером 22 сентября на конференции battery day...</td>\n",
       "      <td>Илон Маск представил планы Tesla по выходу на ...</td>\n",
       "      <td>В ходе конференции Tesla Battery Day, Илон Мас...</td>\n",
       "      <td>- Глава Tesla Илон Маск анонсировал вывод на р...</td>\n",
       "      <td>На конференции Battery Day Илон Маск объявил о...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098891</td>\n",
       "      <td>0.100573</td>\n",
       "      <td>0.146562</td>\n",
       "      <td>0.227205</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.202198</td>\n",
       "      <td>0.251442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Названа опасность постоянно включенного Blueto...   \n",
       "1  Колесникова проходит подозреваемой по делу о з...   \n",
       "2  Deutsche Bank: в мире наступает эпоха беспорядка    \n",
       "3    «Ъ»: Минтранс подготовил проект поправок к ПДД    \n",
       "4  Tesla выпустит бюджетный беспилотник в 2023 году    \n",
       "\n",
       "                                                text  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Аналитики Deutsche Bank обнародовали исследова...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  Вечером 22 сентября на конференции Battery Day...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Активированный в смартфоне Bluetooth может пре...   \n",
       "1  Члена президиума оппозиционного Координационно...   \n",
       "2  В истории человечества наступает эпоха беспоря...   \n",
       "3  Масштабный проект изменений в ПДД подготовили ...   \n",
       "4  Миллиардер Илон Маск пообещал представить бюдж...   \n",
       "\n",
       "                                   mbart_predictions  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  В 2020 году в мире наступит новая эпоха беспор...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  На конференции Battery Day глава Tesla Илон Ма...   \n",
       "\n",
       "                                     mt5_predictions  \\\n",
       "0  Эксперты предупреждают о том, что отключать Bl...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Пандемия коронавируса привела к появлениям нов...   \n",
       "3  В Госдуму вступили в силу поправки в правила д...   \n",
       "4  Илон Маск рассчитывает вывести на рынок бюджет...   \n",
       "\n",
       "                             summarunner_predictions  \\\n",
       "0  постоянно включенный bluetooth на смартфоне гр...   \n",
       "1  член президиума координационного совета оппози...   \n",
       "2  аналитики deutsche bank обнародовали исследова...   \n",
       "3  гибдд совместно с минтрансом разработала масшт...   \n",
       "4  вечером 22 сентября на конференции battery day...   \n",
       "\n",
       "                                llama_7b_predictions  \\\n",
       "0  Bluetooth постоянно включен, это опасно, так к...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...   \n",
       "3  ГИБДД и Минтранс разработали проект изменений ...   \n",
       "4  Илон Маск представил планы Tesla по выходу на ...   \n",
       "\n",
       "                                starling_predictions  \\\n",
       "0  Постоянно включенный Bluetooth может создавать...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предполагают, что 2020...   \n",
       "3  ГИБДД и Минтранс разработали проект изменений ...   \n",
       "4  В ходе конференции Tesla Battery Day, Илон Мас...   \n",
       "\n",
       "                                   yagpt_predictions  \\\n",
       "0  - Постоянно включенный Bluetooth на смартфоне ...   \n",
       "1  - Член президиума координационного совета оппо...   \n",
       "2  - Аналитики Deutsche Bank предсказали наступле...   \n",
       "3  - ГИБДД и Минтранс разработали масштабный прое...   \n",
       "4  - Глава Tesla Илон Маск анонсировал вывод на р...   \n",
       "\n",
       "                                  yagpt3_predictions  ...  \\\n",
       "0  Доцент кафедры информатики РЭУ им. Плеханова А...  ...   \n",
       "1  Мария Колесникова, член президиума координацио...  ...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...  ...   \n",
       "3  ГИБДД совместно с Минтрансом разработали масшт...  ...   \n",
       "4  На конференции Battery Day Илон Маск объявил о...  ...   \n",
       "\n",
       "   mbart_predictions_meteor  mt5_predictions_meteor  \\\n",
       "0                  0.126459                0.053648   \n",
       "1                  0.248829                0.101734   \n",
       "2                  0.309631                0.086664   \n",
       "3                  0.306315                0.082645   \n",
       "4                  0.098891                0.100573   \n",
       "\n",
       "   summarunner_predictions_meteor  llama_7b_predictions_meteor  \\\n",
       "0                        0.168245                     0.207257   \n",
       "1                        0.263807                     0.231588   \n",
       "2                        0.314012                     0.262029   \n",
       "3                        0.233184                     0.256739   \n",
       "4                        0.146562                     0.227205   \n",
       "\n",
       "   starling_predictions_meteor  yagpt_predictions_meteor  \\\n",
       "0                     0.127202                  0.168304   \n",
       "1                     0.310913                  0.327753   \n",
       "2                     0.238650                  0.295642   \n",
       "3                     0.270406                  0.338463   \n",
       "4                     0.193430                  0.202198   \n",
       "\n",
       "   yagpt3_predictions_meteor  mbart_predictions_bleu.1  \\\n",
       "0                   0.139373                       NaN   \n",
       "1                   0.224195                       NaN   \n",
       "2                   0.311487                       NaN   \n",
       "3                   0.296722                       NaN   \n",
       "4                   0.251442                       NaN   \n",
       "\n",
       "   mt5_predictions_bleu.1  summarunner_predictions_bleu.1  \n",
       "0                     NaN                             NaN  \n",
       "1                     NaN                             NaN  \n",
       "2                     NaN                             NaN  \n",
       "3                     NaN                             NaN  \n",
       "4                     NaN                             NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62605a30-dd71-446b-bc4b-c5287c413a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_Актуальность</th>\n",
       "      <th>summary_Последовательность</th>\n",
       "      <th>summary_Беглость</th>\n",
       "      <th>summary_Согласованность</th>\n",
       "      <th>mbart_predictions</th>\n",
       "      <th>mbart_predictions_Актуальность</th>\n",
       "      <th>mbart_predictions_Последовательность</th>\n",
       "      <th>mbart_predictions_Беглость</th>\n",
       "      <th>...</th>\n",
       "      <th>yagpt_predictions</th>\n",
       "      <th>yagpt_predictions_Актуальность</th>\n",
       "      <th>yagpt_predictions_Последовательность</th>\n",
       "      <th>yagpt_predictions_Беглость</th>\n",
       "      <th>yagpt_predictions_Согласованность</th>\n",
       "      <th>yagpt3_predictions</th>\n",
       "      <th>yagpt3_predictions_Актуальность</th>\n",
       "      <th>yagpt3_predictions_Последовательность</th>\n",
       "      <th>yagpt3_predictions_Беглость</th>\n",
       "      <th>yagpt3_predictions_Согласованность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Активированный в смартфоне Bluetooth может пре...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Постоянно включенный Bluetooth на смартфоне ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Доцент кафедры информатики РЭУ им. Плеханова А...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Члена президиума оппозиционного Координационно...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Член президиума координационного совета оппо...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аналитики Deutsche Bank обнародовали исследова...</td>\n",
       "      <td>В истории человечества наступает эпоха беспоря...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>В 2020 году в мире наступит новая эпоха беспор...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Аналитики Deutsche Bank предсказали наступле...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>Масштабный проект изменений в ПДД подготовили ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- ГИБДД и Минтранс разработали масштабный прое...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработали масшт...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вечером 22 сентября на конференции Battery Day...</td>\n",
       "      <td>Миллиардер Илон Маск пообещал представить бюдж...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>На конференции Battery Day глава Tesla Илон Ма...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Глава Tesla Илон Маск анонсировал вывод на р...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>На конференции Battery Day Илон Маск объявил о...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Аналитики Deutsche Bank обнародовали исследова...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  Вечером 22 сентября на конференции Battery Day...   \n",
       "\n",
       "                                             summary  summary_Актуальность  \\\n",
       "0  Активированный в смартфоне Bluetooth может пре...                   5.0   \n",
       "1  Члена президиума оппозиционного Координационно...                   5.0   \n",
       "2  В истории человечества наступает эпоха беспоря...                   5.0   \n",
       "3  Масштабный проект изменений в ПДД подготовили ...                   4.0   \n",
       "4  Миллиардер Илон Маск пообещал представить бюдж...                   4.0   \n",
       "\n",
       "   summary_Последовательность  summary_Беглость  summary_Согласованность  \\\n",
       "0                         5.0               5.0                      5.0   \n",
       "1                         5.0               5.0                      5.0   \n",
       "2                         5.0               5.0                      5.0   \n",
       "3                         5.0               5.0                      5.0   \n",
       "4                         4.0               5.0                      4.0   \n",
       "\n",
       "                                   mbart_predictions  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  В 2020 году в мире наступит новая эпоха беспор...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  На конференции Battery Day глава Tesla Илон Ма...   \n",
       "\n",
       "   mbart_predictions_Актуальность  mbart_predictions_Последовательность  \\\n",
       "0                             4.0                                   4.0   \n",
       "1                             4.0                                   4.0   \n",
       "2                             5.0                                   5.0   \n",
       "3                             5.0                                   5.0   \n",
       "4                             5.0                                   5.0   \n",
       "\n",
       "   mbart_predictions_Беглость  ...  \\\n",
       "0                         5.0  ...   \n",
       "1                         5.0  ...   \n",
       "2                         5.0  ...   \n",
       "3                         4.0  ...   \n",
       "4                         5.0  ...   \n",
       "\n",
       "                                   yagpt_predictions  \\\n",
       "0  - Постоянно включенный Bluetooth на смартфоне ...   \n",
       "1  - Член президиума координационного совета оппо...   \n",
       "2  - Аналитики Deutsche Bank предсказали наступле...   \n",
       "3  - ГИБДД и Минтранс разработали масштабный прое...   \n",
       "4  - Глава Tesla Илон Маск анонсировал вывод на р...   \n",
       "\n",
       "  yagpt_predictions_Актуальность  yagpt_predictions_Последовательность  \\\n",
       "0                            4.0                                   4.0   \n",
       "1                            3.0                                   5.0   \n",
       "2                            2.0                                   5.0   \n",
       "3                            3.0                                   4.0   \n",
       "4                            2.0                                   5.0   \n",
       "\n",
       "   yagpt_predictions_Беглость  yagpt_predictions_Согласованность  \\\n",
       "0                         4.0                                4.0   \n",
       "1                         5.0                                5.0   \n",
       "2                         5.0                                4.0   \n",
       "3                         4.0                                4.0   \n",
       "4                         5.0                                4.0   \n",
       "\n",
       "                                  yagpt3_predictions  \\\n",
       "0  Доцент кафедры информатики РЭУ им. Плеханова А...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...   \n",
       "3  ГИБДД совместно с Минтрансом разработали масшт...   \n",
       "4  На конференции Battery Day Илон Маск объявил о...   \n",
       "\n",
       "  yagpt3_predictions_Актуальность  yagpt3_predictions_Последовательность  \\\n",
       "0                             4.0                                    4.0   \n",
       "1                             3.0                                    3.0   \n",
       "2                             4.0                                    5.0   \n",
       "3                             3.0                                    4.0   \n",
       "4                             4.0                                    5.0   \n",
       "\n",
       "   yagpt3_predictions_Беглость  yagpt3_predictions_Согласованность  \n",
       "0                          5.0                                 5.0  \n",
       "1                          5.0                                 5.0  \n",
       "2                          5.0                                 5.0  \n",
       "3                          5.0                                 4.0  \n",
       "4                          5.0                                 5.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49f45c9-276c-45e4-8946-983294530895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median devs:\n",
      "\tBLEU:  0.08652315462924738 0.5889453306820962\n",
      "\tROUGE:  0.08388135593220336 0.69087546980561\n",
      "\tMETEOR:  0.0933422032178387 0.5547894310323825\n",
      "\tBERTSCORE:  0.08324829339981082 0.510270966206278\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "human_metrics = human_metrics[:-1]\n",
    "\n",
    "models = {\n",
    "    \"mbart_predictions\",\n",
    "    \"mt5_predictions\",\n",
    "    \"summarunner_predictions\",\n",
    "    \"llama_7b_predictions\",\n",
    "    \"starling_predictions\",\n",
    "    \"yagpt_predictions\",\n",
    "    \"yagpt3_predictions\"\n",
    "}\n",
    "metrics = {\n",
    "    \"bleu\",\n",
    "    \"rouge1\",\n",
    "    \"meteor\",\n",
    "    \"bertscore_f1\"\n",
    "}\n",
    "\n",
    "texts = []\n",
    "summaries = []\n",
    "labels = {k: {\"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []} for k in [0.25, 0.5, 0.75]}\n",
    "human_scores = []\n",
    "auto_scores = {\"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []}\n",
    "totals = {\"bleu\": 0, \"bertscore\": 0, \"rouge\": 0, \"meteor\": 0}\n",
    "deviations = {\"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []}\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for (mteric_index, metric_row), (expert_index, expert_row)  in zip(metrics_data.iterrows(), expert_data.iterrows()):\n",
    "        # if any([row[f\"{model}_{metric}\"] is None or math.isnan(row[f\"{model}_{metric}\"]) for metric in metrics]) or row[model] is None or type(row[model]) != str:\n",
    "        #     continue\n",
    "        texts.append(metric_row[\"summary\"])\n",
    "        summaries.append(metric_row[model])\n",
    "        human_scores.append(np.mean([expert_row[f\"{model}_{metric}\"] for metric in human_metrics]) / 5)\n",
    "        # print(model, human_scores[-1])\n",
    "\n",
    "        auto_scores[\"bleu\"].append(metric_row[f\"{model}_bleu\"])\n",
    "        auto_scores[\"rouge\"].append(metric_row[f\"{model}_rouge1\"])\n",
    "        auto_scores[\"meteor\"].append(metric_row[f\"{model}_meteor\"])\n",
    "        auto_scores[\"bertscore\"].append(metric_row[f\"{model}_bertscore_f1\"])\n",
    "\n",
    "mean_human = np.mean(human_scores)\n",
    "mean_bleu = np.mean(auto_scores[\"bleu\"])\n",
    "mean_rouge = np.mean(auto_scores[\"rouge\"])\n",
    "mean_meteor = np.mean(auto_scores[\"meteor\"])\n",
    "mean_bertscore = np.mean(auto_scores[\"bertscore\"])\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    human_scores[i] -= mean_human\n",
    "    auto_scores[\"bleu\"][i] -= mean_bleu\n",
    "    auto_scores[\"rouge\"][i] -= mean_rouge\n",
    "    auto_scores[\"meteor\"][i] -= mean_meteor\n",
    "    auto_scores[\"bertscore\"][i] -= mean_bertscore\n",
    "\n",
    "    deviations[\"bleu\"].append(abs(auto_scores[\"bleu\"][i] - human_scores[i]))\n",
    "    deviations[\"rouge\"].append(abs(auto_scores[\"rouge\"][i] - human_scores[i]))\n",
    "    deviations[\"meteor\"].append(abs(auto_scores[\"meteor\"][i] - human_scores[i]))\n",
    "    deviations[\"bertscore\"].append(abs(auto_scores[\"bertscore\"][i] - human_scores[i]))\n",
    "\n",
    "print(\"Median devs:\")\n",
    "print(\"\\tBLEU: \", np.median(deviations[\"bleu\"]), np.max(deviations[\"bleu\"]))\n",
    "print(\"\\tROUGE: \", np.median(deviations[\"rouge\"]), np.max(deviations[\"rouge\"]))\n",
    "print(\"\\tMETEOR: \", np.median(deviations[\"meteor\"]), np.max(deviations[\"meteor\"]))\n",
    "print(\"\\tBERTSCORE: \", np.median(deviations[\"bertscore\"]), np.max(deviations[\"bertscore\"]))\n",
    "\n",
    "for k in [0.25, 0.5, 0.75]:\n",
    "    labels[k][\"bleu\"] = [1.0 if deviations[\"bleu\"][i] < np.quantile(deviations[\"bleu\"], k) else 0.0 for i in range(len(texts))]\n",
    "    labels[k][\"rouge\"] = [1.0 if deviations[\"rouge\"][i] < np.quantile(deviations[\"rouge\"], k) else 0.0 for i in range(len(texts))]\n",
    "    labels[k][\"meteor\"] = [1.0 if deviations[\"meteor\"][i] < np.quantile(deviations[\"meteor\"], k) else 0.0 for i in range(len(texts))]\n",
    "    labels[k][\"bertscore\"] = [1.0 if deviations[\"bertscore\"][i] < np.quantile(deviations[\"bertscore\"], k) else 0.0  for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08d7b099-0446-4737-9bad-961cb09fa804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Попробуйте обработать утюжок по всей длине волос, от корней до кончиков, а не карандаш.\\n', 'В очередной подборке интересных научных новостей недели:\\n', 'Если вы хотите покопаться в гнезде роющих ос, то наверняка узнаете, что они могут укусить вас.\\n', 'В мире есть множество способов повысить физическую форму.\\n', 'Таиландские лабео - одна из самых опасных рыб в мире, однако, как выяснила обозреватель BBC Earth, они очень агрессивные к представителям своего вида.\\n']\n",
      "['Расчешите волосы расческой или щеткой. Выделите тонкую прядь волос и завейте ее вокруг карандаша. Возьмите утюжок для выпрямления волос и прижмите им волосы, обернутые вокруг карандаша. Без спешки распустите волосы, сняв их с карандаша. Нанесите лак для волос.', 'По возможности расспросите ветеринара о состоянии рыбки. Изучите информацию о виде своей рыбки. Держите больную рыбу в спокойной обстановке. Не кормите рыбку за 24–48 часов до медикаментозной эвтаназии. Проведите эвтаназию одним из указанных далее способов.', 'Узнайте больше, о роющих осах. Определите признаки, по которым можно определить, что ваша лужайка, или огород уже заражены роющими осами. Определите сезон, в который осы появляются чаще всего. Очень важно понимать, что такие осы жалят только тогда, когда на них нападают.', 'Занимайтесь спортом. Гуляйте на природе. Спите достаточное количество времени. Станьте волонтером. Налаживайте отношения и обеспечьте себя поддержкой.', 'Выберите в качестве соседей достаточно агрессивных рыбок. Предусмотрите места для укрытия. Не рассчитывайте на то, что вам удастся получить потомство таиландских лабео.']\n"
     ]
    }
   ],
   "source": [
    "print(summaries[695:])\n",
    "print(texts[695:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b69e70-42fa-4940-8643-e1bc686e5011",
   "metadata": {},
   "source": [
    "## Dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f5be1a-3f62-4e9b-9a7a-4b2b3c8d1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_dataset(tokenizer, metric_name, k):\n",
    "    texts_len = len(texts)\n",
    "    train = int(texts_len * 0.9)\n",
    "    test_val = int(texts_len * 0.1)\n",
    "    # max_length = 512\n",
    "    return {\n",
    "        \"train\": MetricsCorrelationDataset(texts=texts[0:train], summaries=summaries[0:train], labels=labels[k][metric_name][0:train], tokenizer=tokenizer, max_length=max_length),\n",
    "        \"test\": MetricsCorrelationDataset(texts=texts[train:texts_len], summaries=summaries[train:texts_len], labels=labels[k][metric_name][train:texts_len], tokenizer=tokenizer, max_length=max_length),\n",
    "        #\"val\": MetricsCorrelationDataset(texts=texts[train + test_val:train + 2 * test_val], summaries=summaries[train + test_val:train + 2 * test_val], labels=labels[metric_name][train + test_val:train + 2 * test_val], tokenizer=tokenizer, max_length=max_length)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b38bb-b128-41e8-8947-726948337755",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbaa10d-82f8-4366-8db1-f684b0c86813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53caa826-7577-41b2-88b2-4694c10df058",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"automatic_predictor\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a37ced-33e4-4de1-bddc-c909867b4376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7c2401-d8ed-4960-8af9-16c980306a88",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ec669e-1962-43c6-a73b-fe311b9b377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probabilities = np.exp(predictions) / np.sum(np.exp(predictions), axis=-1, keepdims=True)\n",
    "    predictions = torch.tensor([float(round(x)) for x in predictions.flatten()])\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
    "    p = precision_score(labels, predictions, average=\"macro\")\n",
    "    r = recall_score(labels, predictions, average=\"macro\")\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451ebaa1-4c99-46ea-b1cd-79df891b59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptEncoderConfig,\n",
    "    LoraConfig,\n",
    "    LoraModel\n",
    ")\n",
    "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=30, encoder_hidden_size=256)\n",
    "\n",
    "# config = LoraConfig(\n",
    "#     task_type=\"SEQ_2_SEQ_LM\",\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"query\", \"value\"],\n",
    "#     lora_dropout=0.01,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099df800-94a6-4663-b7a3-1d007364c18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "809cfff7-d686-474c-8fea-cff841bc7c24",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219140d-98f2-43de-8a4f-9e959d3bdfa8",
   "metadata": {},
   "source": [
    "## K=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35915de9-0a18-413b-b4b4-c170e2fc9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db324cfd-d4ba-4f3f-8b8e-55a312b73b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt5_predictions'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685406a5-76c4-452b-9338-1f5af71d1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='106' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 106/3150 00:14 < 07:18, 6.94 it/s, Epoch 0.50/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [458,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     15\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:337\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:260\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    256\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "\n",
    "# model = LoraModel(model, config, \"default\")\n",
    "#model = get_peft_model(model, config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "# tokenizer.model_max_length=514\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"bleu\", 0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51068ad8-0f4e-48b8-9537-ab308d3b7e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f795ebd-2f99-47a5-bd85-fc50fcb90b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10625a-337a-457d-8173-58783c16af33",
   "metadata": {},
   "source": [
    "### Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1914bd3-ad3e-46ca-b3ba-7238426fecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "643af483-1e56-4d2d-bfc3-73e4a2b2233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 357,033,474 || trainable%: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3151' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 04:15, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.382715</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258838</td>\n",
       "      <td>0.450175</td>\n",
       "      <td>0.453431</td>\n",
       "      <td>0.445833</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.268265</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.355408</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.281692</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.468954</td>\n",
       "      <td>0.353741</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.243493</td>\n",
       "      <td>0.470516</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470456</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.247887</td>\n",
       "      <td>0.558908</td>\n",
       "      <td>0.533497</td>\n",
       "      <td>0.481961</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.263486</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>0.511438</td>\n",
       "      <td>0.412611</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.259160</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.468954</td>\n",
       "      <td>0.353741</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.257431</td>\n",
       "      <td>0.532389</td>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.471517</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.272855</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.253364</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.565359</td>\n",
       "      <td>0.547804</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.574346</td>\n",
       "      <td>0.568257</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>0.537928</td>\n",
       "      <td>0.533497</td>\n",
       "      <td>0.516635</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.247639</td>\n",
       "      <td>0.563738</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.552670</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"rouge\", 0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b139a902-405f-4d98-ba6d-e9823b08b983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): ModulesToSaveWrapper(\n",
       "      (original_module): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "      )\n",
       "      (modules_to_save): ModuleDict(\n",
       "        (default): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PromptEncoder(\n",
       "      (embedding): Embedding(30, 1024)\n",
       "      (mlp_head): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08e89e71-9f3b-4788-b71e-18d6c56bdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273400ce-f0ba-4167-a629-703dae044f38",
   "metadata": {},
   "source": [
    "### Bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32669fdc-3ae1-47cb-9adb-af23d9c10128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 357,033,474 || trainable%: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3151' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 04:19, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247336</td>\n",
       "      <td>0.487791</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.479741</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.225914</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.426418</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>0.239834</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>0.258104</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.336130</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.591543</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.246795</td>\n",
       "      <td>0.549959</td>\n",
       "      <td>0.553322</td>\n",
       "      <td>0.545930</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.231391</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.534965</td>\n",
       "      <td>0.482095</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.237157</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.539336</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.232065</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.380531</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.249968</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.561189</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.239173</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.542832</td>\n",
       "      <td>0.504390</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.482026</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.256012</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.554196</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.243946</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbertscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"bertscore\", k=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45d82158-57fb-4ec5-a067-be3ddcad0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a057d-4eba-4aba-b4fa-53babef1a92b",
   "metadata": {},
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f1ceb8b-2d70-4b95-82be-851c9507bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1483' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1483/3150 04:24 < 04:58, 5.59 it/s, Epoch 7.06/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253531</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255761</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>0.331028</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>0.309653</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.247108</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.305088</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.252760</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2221\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"meteor\", k=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c5414-deed-47b5-87f2-a5faf118fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83b5fb-0657-4845-a29b-af9d42f02b17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## K=0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fc570-8b6a-4cdf-867f-16e83dd26ec6",
   "metadata": {},
   "source": [
    "# ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b745d-d01b-48b4-a6d8-fe55decd56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7736f5-396e-437d-98f2-32e9cf66860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ee0c0e-8030-41e9-bdee-967faa6aa57f",
   "metadata": {},
   "source": [
    "## BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6a0376-640c-4f21-80ad-60445bad3dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruElectra-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 428,582,402 || trainable%: 0.3903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 05:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305537</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294317</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.289797</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.259369</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>0.313369</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>0.300057</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>0.275571</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.325151</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.285546</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.290005</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.50\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruElectra-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruElectra-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"bleu\", 0.50)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fb2f7-c3c9-4d3a-90a4-f01f73f8cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42dc47-a1f7-4302-b15b-c21eab2b5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617022b-6683-4138-a433-2b8fcdd94ebf",
   "metadata": {},
   "source": [
    "### Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc82857-6fff-4670-a207-d488780727c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a20912-5091-4da8-b671-f41086f5cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruElectra-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 428,582,402 || trainable%: 0.3903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 05:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291069</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.271982</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.353613</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.280487</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.283094</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.276100</td>\n",
       "      <td>0.274621</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.299621</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.293541</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.291606</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 1e6cc398-e690-466e-9a1c-9c7268a1b8c8)') - silently ignoring the lookup for the file config.json in ai-forever/ruElectra-large.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in ai-forever/ruElectra-large - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.50\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruElectra-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruElectra-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"rouge\", 0.50)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df014b26-dc6c-44e3-831e-1625edfddf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df9697-a2d3-40ee-ab87-290006bd9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610cd2f-0101-401a-85ce-b2369a568b96",
   "metadata": {},
   "source": [
    "### Bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa844ff-5558-453f-9d09-eb034fc09b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruElectra-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 428,582,402 || trainable%: 0.3903\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 05:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265064</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.557143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240751</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.256923</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.281591</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.273623</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.242673</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.270300</td>\n",
       "      <td>0.239930</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.245713</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.240915</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.242676</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbertscore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.50\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruElectra-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruElectra-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"bertscore\", 0.50)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ca6f3-5fb3-4dbe-bb2b-e43152e704c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f9f6e-975f-4bd1-aecc-811e08425123",
   "metadata": {},
   "source": [
    "### METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57017ced-b5d9-4f61-aec9-af4b90d1e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 357,033,474 || trainable%: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 05:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304983</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262649</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.271917</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.356842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.296755</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.287252</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.393698</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.279386</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.286523</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.273500</td>\n",
       "      <td>0.287622</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"meteor\", k=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561e88a-8ba8-4e14-a12b-b97b245986a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab3d36-5ec2-4bb8-8534-8fc5caf7c078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db932f-2e42-4340-9115-2c844bbd7b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eca2e0-ba0c-47be-8d83-c49cf106a02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98823a8-7c40-4bd8-9593-cd28b58130e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0085fe90-993c-4e0d-be47-31c267dbe18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e04fe5-3fc3-4761-b7c0-830740afa13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e654d9000b4c08922360a6c580c485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRLHFlow/ArmoRM-Llama3-8B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(path, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:3754\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3745\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3747\u001b[0m     (\n\u001b[1;32m   3748\u001b[0m         model,\n\u001b[1;32m   3749\u001b[0m         missing_keys,\n\u001b[1;32m   3750\u001b[0m         unexpected_keys,\n\u001b[1;32m   3751\u001b[0m         mismatched_keys,\n\u001b[1;32m   3752\u001b[0m         offload_index,\n\u001b[1;32m   3753\u001b[0m         error_msgs,\n\u001b[0;32m-> 3754\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3761\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3765\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3766\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3774\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:4214\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4210\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4211\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4212\u001b[0m                 )\n\u001b[1;32m   4213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4214\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4215\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4216\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4218\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4221\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4222\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4225\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4229\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4231\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:887\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    876\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m ):\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    889\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/utils/modeling.py:400\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 400\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "path = \"RLHFlow/ArmoRM-Llama3-8B-v0.1\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path, device_map=\"cuda\", \n",
    "                               trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, use_fast=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927eb9e7-2d08-452a-8626-50393be731aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_dataset = get_dataset(tokenizer, \"meteor\", k=0.75)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332ae0f-cebd-43fb-9bb2-a303ccb4a979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d9ccd09-5a8f-4eb8-b5b2-d0abe57b422b",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2302333-002d-4829-880a-97b2090d2358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816bf0c-170c-49d5-be83-6e4a880a5efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8052d43-02e9-4d47-8709-e823fd4bb5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e54307-d6c8-445b-a7c4-1415d2136c69",
   "metadata": {},
   "source": [
    "# Most correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a849491e-4088-43dd-ad70-9190314ec128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median devs:\n",
      "\tMETEOR:  0.15108287373274837 0.8115955489002815\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "human_metrics = [x for x in human_metrics[:-1] if \"Последовательность\" in x]\n",
    "\n",
    "models = {\n",
    "    \"mbart_predictions\",\n",
    "    \"mt5_predictions\",\n",
    "    \"summarunner_predictions\",\n",
    "    \"llama_7b_predictions\",\n",
    "    \"starling_predictions\",\n",
    "    \"yagpt_predictions\",\n",
    "    \"yagpt3_predictions\"\n",
    "}\n",
    "metrics = {\n",
    "    \"meteor\"\n",
    "}\n",
    "\n",
    "texts = []\n",
    "summaries = []\n",
    "labels = {k: {\"meteor\": []} for k in [0.5]}\n",
    "human_scores = []\n",
    "auto_scores = {\"meteor\": []}\n",
    "totals = {\"meteor\": 0}\n",
    "deviations = {\"meteor\": []}\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for (mteric_index, metric_row), (expert_index, expert_row)  in zip(metrics_data.iterrows(), expert_data.iterrows()):\n",
    "        # if any([row[f\"{model}_{metric}\"] is None or math.isnan(row[f\"{model}_{metric}\"]) for metric in metrics]) or row[model] is None or type(row[model]) != str:\n",
    "        #     continue\n",
    "        texts.append(metric_row[\"text\"])\n",
    "        summaries.append(metric_row[model])\n",
    "        human_scores.append(np.mean([expert_row[f\"{model}_{metric}\"] for metric in human_metrics]) / 5)\n",
    "        # print(model, human_scores[-1])\n",
    "\n",
    "        auto_scores[\"meteor\"].append(metric_row[f\"{model}_meteor\"])\n",
    "mean_human = np.mean(human_scores)\n",
    "mean_meteor = np.mean(auto_scores[\"meteor\"])\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    human_scores[i] -= mean_human\n",
    "    auto_scores[\"meteor\"][i] -= mean_meteor\n",
    "\n",
    "    deviations[\"meteor\"].append(abs(auto_scores[\"meteor\"][i] - human_scores[i]))\n",
    "   \n",
    "print(\"Median devs:\")\n",
    "print(\"\\tMETEOR: \", np.median(deviations[\"meteor\"]), np.max(deviations[\"meteor\"]))\n",
    "\n",
    "for k in [0.5]:\n",
    "    labels[k][\"meteor\"] = [1.0 if deviations[\"meteor\"][i] < np.quantile(deviations[\"meteor\"], k) else 0.0 for i in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1a6c70-5f05-4e57-ae4d-edc04aad0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_dataset(tokenizer, metric_name, k):\n",
    "    texts_len = len(texts)\n",
    "    train = int(texts_len * 0.9)\n",
    "    test_val = int(texts_len * 0.1)\n",
    "    max_length = 512\n",
    "    return {\n",
    "        \"train\": MetricsCorrelationDataset(texts=texts[0:train], summaries=summaries[0:train], labels=labels[k][metric_name][0:train], tokenizer=tokenizer, max_length=max_length),\n",
    "        \"test\": MetricsCorrelationDataset(texts=texts[train:texts_len], summaries=summaries[train:texts_len], labels=labels[k][metric_name][train:texts_len], tokenizer=tokenizer, max_length=max_length),\n",
    "        #\"val\": MetricsCorrelationDataset(texts=texts[train + test_val:train + 2 * test_val], summaries=summaries[train + test_val:train + 2 * test_val], labels=labels[metric_name][train + test_val:train + 2 * test_val], tokenizer=tokenizer, max_length=max_length)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81b749-d5d1-417a-8126-8f7fd26baad6",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab239bbb-d7fc-43e8-867a-04ee84957354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31030749-8d75-45f9-98d0-2c188c088c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"automatic_predictor\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f54168-933a-4135-af7e-c99a9755785b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caa8fac9-e04f-457a-a3dd-bbf4b94db03c",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5463a964-ce11-483b-a52e-345fd770af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probabilities = np.exp(predictions) / np.sum(np.exp(predictions), axis=-1, keepdims=True)\n",
    "    predictions = torch.tensor([float(round(x)) for x in predictions.flatten()])\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
    "    p = precision_score(labels, predictions, average=\"macro\")\n",
    "    r = recall_score(labels, predictions, average=\"macro\")\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3adcd7f-4707-46db-b65b-54055e6c5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptEncoderConfig,\n",
    ")\n",
    "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=30, encoder_hidden_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cec55f2a-a150-48b5-89e2-a5e44b1ad27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 357,033,474 || trainable%: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 05:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466658</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.442857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267806</td>\n",
       "      <td>0.570768</td>\n",
       "      <td>0.563275</td>\n",
       "      <td>0.536807</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.276626</td>\n",
       "      <td>0.417004</td>\n",
       "      <td>0.449132</td>\n",
       "      <td>0.403409</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.281267</td>\n",
       "      <td>0.557765</td>\n",
       "      <td>0.550455</td>\n",
       "      <td>0.520647</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.270674</td>\n",
       "      <td>0.504934</td>\n",
       "      <td>0.504963</td>\n",
       "      <td>0.499898</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.272758</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.488420</td>\n",
       "      <td>0.487340</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.265915</td>\n",
       "      <td>0.501068</td>\n",
       "      <td>0.500827</td>\n",
       "      <td>0.481947</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.267600</td>\n",
       "      <td>0.275343</td>\n",
       "      <td>0.492142</td>\n",
       "      <td>0.492142</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.267600</td>\n",
       "      <td>0.268625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520678</td>\n",
       "      <td>0.520647</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.268643</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520678</td>\n",
       "      <td>0.520647</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2339\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2337\u001b[0m         smp\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[38;5;66;03m# add remaining tr_loss\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_loss_scalar \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2629\u001b[0m, in \u001b[0;36mTrainer._load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2625\u001b[0m     model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2626\u001b[0m ):\n\u001b[1;32m   2627\u001b[0m     \u001b[38;5;66;03m# For BC for older PEFT versions\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_adapters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2629\u001b[0m         active_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mactive_adapters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2631\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected multiple active adapters, will only consider the first one\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"meteor\", k=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dcbcf-c343-40d3-a625-59a7769f45f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead6695-60ae-48b4-97c0-976942672440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e6d79-ba7c-420a-933a-b116d0525c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb5e4d-5bf6-46db-8772-36e0a0a30c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e75dec-ac22-4bc8-8122-af369b5957d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59709033-d7c4-4d04-b19a-5754873a45f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922be5fa-d8e1-48a3-bb59-ee08068f79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c60f7-fdc2-41fb-b0dd-ca3951e3807f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04099b0-8c32-45ba-a845-a391f58f45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCorrelationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, summaries, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.summaries = summaries\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        summary = self.summaries[idx]\n",
    "        label = self.labels[idx]\n",
    "        text_encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        summary_encoding = self.tokenizer(summary, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        encoding = self.tokenizer(text, summary, truncation='only_first')\n",
    "        ans = {\n",
    "            # 'text_input_ids': text_encoding['input_ids'].flatten(), \n",
    "            # 'text_attention_mask': text_encoding['attention_mask'].flatten(), \n",
    "            # 'summary_input_ids': summary_encoding['input_ids'].flatten(),\n",
    "            # 'summary_attention_mask': summary_encoding['attention_mask'].flatten(),\n",
    "            'input_ids': encoding['input_ids'],\n",
    "            'attention_mask': encoding['attention_mask'],\n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "        \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bd8b3-800a-45ac-bfc4-0adee032327e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f826c2c-a098-415b-bb54-8d1ca2eb50c0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c062ef-7c5e-48dd-9ed6-c16c5c2508e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': <class 'str'>, 'summary_Актуальность': 'Float64', 'summary_Последовательность': 'Float64', 'summary_Беглость': 'Float64', 'summary_Согласованность': 'Float64', 'summary_Комментарий': <class 'str'>, 'mbart_predictions': <class 'str'>, 'mbart_predictions_Актуальность': 'Float64', 'mbart_predictions_Последовательность': 'Float64', 'mbart_predictions_Беглость': 'Float64', 'mbart_predictions_Согласованность': 'Float64', 'mbart_predictions_Комментарий': <class 'str'>, 'mt5_predictions': <class 'str'>, 'mt5_predictions_Актуальность': 'Float64', 'mt5_predictions_Последовательность': 'Float64', 'mt5_predictions_Беглость': 'Float64', 'mt5_predictions_Согласованность': 'Float64', 'mt5_predictions_Комментарий': <class 'str'>, 'summarunner_predictions': <class 'str'>, 'summarunner_predictions_Актуальность': 'Float64', 'summarunner_predictions_Последовательность': 'Float64', 'summarunner_predictions_Беглость': 'Float64', 'summarunner_predictions_Согласованность': 'Float64', 'summarunner_predictions_Комментарий': <class 'str'>, 'llama_7b_predictions': <class 'str'>, 'llama_7b_predictions_Актуальность': 'Float64', 'llama_7b_predictions_Последовательность': 'Float64', 'llama_7b_predictions_Беглость': 'Float64', 'llama_7b_predictions_Согласованность': 'Float64', 'llama_7b_predictions_Комментарий': <class 'str'>, 'starling_predictions': <class 'str'>, 'starling_predictions_Актуальность': 'Float64', 'starling_predictions_Последовательность': 'Float64', 'starling_predictions_Беглость': 'Float64', 'starling_predictions_Согласованность': 'Float64', 'starling_predictions_Комментарий': <class 'str'>, 'yagpt_predictions': <class 'str'>, 'yagpt_predictions_Актуальность': 'Float64', 'yagpt_predictions_Последовательность': 'Float64', 'yagpt_predictions_Беглость': 'Float64', 'yagpt_predictions_Согласованность': 'Float64', 'yagpt_predictions_Комментарий': <class 'str'>, 'yagpt3_predictions': <class 'str'>, 'yagpt3_predictions_Актуальность': 'Float64', 'yagpt3_predictions_Последовательность': 'Float64', 'yagpt3_predictions_Беглость': 'Float64', 'yagpt3_predictions_Согласованность': 'Float64', 'yagpt3_predictions_Комментарий': <class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "index = \"Ind\"\n",
    "title = \"title\"\n",
    "article = \"text\"\n",
    "ground_truth = \"summary\"\n",
    "\n",
    "files = [\n",
    "    f\"{ground_truth}.txt\", # Dummy for summary field\n",
    "    \"mbart_predictions.txt\",\n",
    "    \"mt5_predictions.txt\",\n",
    "    \"summarunner_predictions.txt\",\n",
    "    \"llama_7b_predictions.csv\",\n",
    "    \"starling_predictions.csv\",\n",
    "    \"yagpt_predictions.csv\",\n",
    "    \"yagpt3_predictions.csv\"\n",
    "]\n",
    "summaries_fields = []\n",
    "human_metrics = [\n",
    "    \"Актуальность\",\n",
    "    \"Последовательность\",\n",
    "    \"Беглость\",\n",
    "    \"Согласованность\",\n",
    "    \"Комментарий\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    model_name = file.split(\".\")[0]\n",
    "    summaries_fields.append(model_name)\n",
    "    for metric in human_metrics:\n",
    "        summaries_fields.append(f\"{model_name}_{metric}\")\n",
    "\n",
    "summaries_fields_types = {field : ('Float64' if field.split(\"_\")[-1] != human_metrics[-1] and field + \".txt\" not in files and field + \".csv\" not in files else str) for field in summaries_fields}\n",
    "print(summaries_fields_types)\n",
    "summaries_fields_types[index] = 'Int64'\n",
    "summaries_fields_types[article] = summaries_fields_types[ground_truth] = str\n",
    "\n",
    "metrics_data = pd.read_csv(\"metrics_data.csv\", dtype=summaries_fields_types)\n",
    "expert_data = pd.read_csv(\"compiled_expert_data.csv\", dtype=summaries_fields_types)\n",
    "# data = pd.read_csv(\"export_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbc2688-fba7-4231-af67-7d667ef57a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>mbart_predictions</th>\n",
       "      <th>mt5_predictions</th>\n",
       "      <th>summarunner_predictions</th>\n",
       "      <th>llama_7b_predictions</th>\n",
       "      <th>starling_predictions</th>\n",
       "      <th>yagpt_predictions</th>\n",
       "      <th>yagpt3_predictions</th>\n",
       "      <th>...</th>\n",
       "      <th>mbart_predictions_meteor</th>\n",
       "      <th>mt5_predictions_meteor</th>\n",
       "      <th>summarunner_predictions_meteor</th>\n",
       "      <th>llama_7b_predictions_meteor</th>\n",
       "      <th>starling_predictions_meteor</th>\n",
       "      <th>yagpt_predictions_meteor</th>\n",
       "      <th>yagpt3_predictions_meteor</th>\n",
       "      <th>mbart_predictions_bleu.1</th>\n",
       "      <th>mt5_predictions_bleu.1</th>\n",
       "      <th>summarunner_predictions_bleu.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Названа опасность постоянно включенного Blueto...</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Активированный в смартфоне Bluetooth может пре...</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Эксперты предупреждают о том, что отключать Bl...</td>\n",
       "      <td>постоянно включенный bluetooth на смартфоне гр...</td>\n",
       "      <td>Bluetooth постоянно включен, это опасно, так к...</td>\n",
       "      <td>Постоянно включенный Bluetooth может создавать...</td>\n",
       "      <td>- Постоянно включенный Bluetooth на смартфоне ...</td>\n",
       "      <td>Доцент кафедры информатики РЭУ им. Плеханова А...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126459</td>\n",
       "      <td>0.053648</td>\n",
       "      <td>0.168245</td>\n",
       "      <td>0.207257</td>\n",
       "      <td>0.127202</td>\n",
       "      <td>0.168304</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Колесникова проходит подозреваемой по делу о з...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Члена президиума оппозиционного Координационно...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>член президиума координационного совета оппози...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>- Член президиума координационного совета оппо...</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248829</td>\n",
       "      <td>0.101734</td>\n",
       "      <td>0.263807</td>\n",
       "      <td>0.231588</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.327753</td>\n",
       "      <td>0.224195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deutsche Bank: в мире наступает эпоха беспорядка</td>\n",
       "      <td>Аналитики Deutsche Bank обнародовали исследова...</td>\n",
       "      <td>В истории человечества наступает эпоха беспоря...</td>\n",
       "      <td>В 2020 году в мире наступит новая эпоха беспор...</td>\n",
       "      <td>Пандемия коронавируса привела к появлениям нов...</td>\n",
       "      <td>аналитики deutsche bank обнародовали исследова...</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>Аналитики Deutsche Bank предполагают, что 2020...</td>\n",
       "      <td>- Аналитики Deutsche Bank предсказали наступле...</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309631</td>\n",
       "      <td>0.086664</td>\n",
       "      <td>0.314012</td>\n",
       "      <td>0.262029</td>\n",
       "      <td>0.238650</td>\n",
       "      <td>0.295642</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Ъ»: Минтранс подготовил проект поправок к ПДД</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>Масштабный проект изменений в ПДД подготовили ...</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>В Госдуму вступили в силу поправки в правила д...</td>\n",
       "      <td>гибдд совместно с минтрансом разработала масшт...</td>\n",
       "      <td>ГИБДД и Минтранс разработали проект изменений ...</td>\n",
       "      <td>ГИБДД и Минтранс разработали проект изменений ...</td>\n",
       "      <td>- ГИБДД и Минтранс разработали масштабный прое...</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработали масшт...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306315</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.233184</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.270406</td>\n",
       "      <td>0.338463</td>\n",
       "      <td>0.296722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesla выпустит бюджетный беспилотник в 2023 году</td>\n",
       "      <td>Вечером 22 сентября на конференции Battery Day...</td>\n",
       "      <td>Миллиардер Илон Маск пообещал представить бюдж...</td>\n",
       "      <td>На конференции Battery Day глава Tesla Илон Ма...</td>\n",
       "      <td>Илон Маск рассчитывает вывести на рынок бюджет...</td>\n",
       "      <td>вечером 22 сентября на конференции battery day...</td>\n",
       "      <td>Илон Маск представил планы Tesla по выходу на ...</td>\n",
       "      <td>В ходе конференции Tesla Battery Day, Илон Мас...</td>\n",
       "      <td>- Глава Tesla Илон Маск анонсировал вывод на р...</td>\n",
       "      <td>На конференции Battery Day Илон Маск объявил о...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098891</td>\n",
       "      <td>0.100573</td>\n",
       "      <td>0.146562</td>\n",
       "      <td>0.227205</td>\n",
       "      <td>0.193430</td>\n",
       "      <td>0.202198</td>\n",
       "      <td>0.251442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Названа опасность постоянно включенного Blueto...   \n",
       "1  Колесникова проходит подозреваемой по делу о з...   \n",
       "2  Deutsche Bank: в мире наступает эпоха беспорядка    \n",
       "3    «Ъ»: Минтранс подготовил проект поправок к ПДД    \n",
       "4  Tesla выпустит бюджетный беспилотник в 2023 году    \n",
       "\n",
       "                                                text  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Аналитики Deutsche Bank обнародовали исследова...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  Вечером 22 сентября на конференции Battery Day...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Активированный в смартфоне Bluetooth может пре...   \n",
       "1  Члена президиума оппозиционного Координационно...   \n",
       "2  В истории человечества наступает эпоха беспоря...   \n",
       "3  Масштабный проект изменений в ПДД подготовили ...   \n",
       "4  Миллиардер Илон Маск пообещал представить бюдж...   \n",
       "\n",
       "                                   mbart_predictions  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  В 2020 году в мире наступит новая эпоха беспор...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  На конференции Battery Day глава Tesla Илон Ма...   \n",
       "\n",
       "                                     mt5_predictions  \\\n",
       "0  Эксперты предупреждают о том, что отключать Bl...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Пандемия коронавируса привела к появлениям нов...   \n",
       "3  В Госдуму вступили в силу поправки в правила д...   \n",
       "4  Илон Маск рассчитывает вывести на рынок бюджет...   \n",
       "\n",
       "                             summarunner_predictions  \\\n",
       "0  постоянно включенный bluetooth на смартфоне гр...   \n",
       "1  член президиума координационного совета оппози...   \n",
       "2  аналитики deutsche bank обнародовали исследова...   \n",
       "3  гибдд совместно с минтрансом разработала масшт...   \n",
       "4  вечером 22 сентября на конференции battery day...   \n",
       "\n",
       "                                llama_7b_predictions  \\\n",
       "0  Bluetooth постоянно включен, это опасно, так к...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...   \n",
       "3  ГИБДД и Минтранс разработали проект изменений ...   \n",
       "4  Илон Маск представил планы Tesla по выходу на ...   \n",
       "\n",
       "                                starling_predictions  \\\n",
       "0  Постоянно включенный Bluetooth может создавать...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предполагают, что 2020...   \n",
       "3  ГИБДД и Минтранс разработали проект изменений ...   \n",
       "4  В ходе конференции Tesla Battery Day, Илон Мас...   \n",
       "\n",
       "                                   yagpt_predictions  \\\n",
       "0  - Постоянно включенный Bluetooth на смартфоне ...   \n",
       "1  - Член президиума координационного совета оппо...   \n",
       "2  - Аналитики Deutsche Bank предсказали наступле...   \n",
       "3  - ГИБДД и Минтранс разработали масштабный прое...   \n",
       "4  - Глава Tesla Илон Маск анонсировал вывод на р...   \n",
       "\n",
       "                                  yagpt3_predictions  ...  \\\n",
       "0  Доцент кафедры информатики РЭУ им. Плеханова А...  ...   \n",
       "1  Мария Колесникова, член президиума координацио...  ...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...  ...   \n",
       "3  ГИБДД совместно с Минтрансом разработали масшт...  ...   \n",
       "4  На конференции Battery Day Илон Маск объявил о...  ...   \n",
       "\n",
       "   mbart_predictions_meteor  mt5_predictions_meteor  \\\n",
       "0                  0.126459                0.053648   \n",
       "1                  0.248829                0.101734   \n",
       "2                  0.309631                0.086664   \n",
       "3                  0.306315                0.082645   \n",
       "4                  0.098891                0.100573   \n",
       "\n",
       "   summarunner_predictions_meteor  llama_7b_predictions_meteor  \\\n",
       "0                        0.168245                     0.207257   \n",
       "1                        0.263807                     0.231588   \n",
       "2                        0.314012                     0.262029   \n",
       "3                        0.233184                     0.256739   \n",
       "4                        0.146562                     0.227205   \n",
       "\n",
       "   starling_predictions_meteor  yagpt_predictions_meteor  \\\n",
       "0                     0.127202                  0.168304   \n",
       "1                     0.310913                  0.327753   \n",
       "2                     0.238650                  0.295642   \n",
       "3                     0.270406                  0.338463   \n",
       "4                     0.193430                  0.202198   \n",
       "\n",
       "   yagpt3_predictions_meteor  mbart_predictions_bleu.1  \\\n",
       "0                   0.139373                       NaN   \n",
       "1                   0.224195                       NaN   \n",
       "2                   0.311487                       NaN   \n",
       "3                   0.296722                       NaN   \n",
       "4                   0.251442                       NaN   \n",
       "\n",
       "   mt5_predictions_bleu.1  summarunner_predictions_bleu.1  \n",
       "0                     NaN                             NaN  \n",
       "1                     NaN                             NaN  \n",
       "2                     NaN                             NaN  \n",
       "3                     NaN                             NaN  \n",
       "4                     NaN                             NaN  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b96483-513a-4ce2-8094-48dbd33c83eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_Актуальность</th>\n",
       "      <th>summary_Последовательность</th>\n",
       "      <th>summary_Беглость</th>\n",
       "      <th>summary_Согласованность</th>\n",
       "      <th>mbart_predictions</th>\n",
       "      <th>mbart_predictions_Актуальность</th>\n",
       "      <th>mbart_predictions_Последовательность</th>\n",
       "      <th>mbart_predictions_Беглость</th>\n",
       "      <th>...</th>\n",
       "      <th>yagpt_predictions</th>\n",
       "      <th>yagpt_predictions_Актуальность</th>\n",
       "      <th>yagpt_predictions_Последовательность</th>\n",
       "      <th>yagpt_predictions_Беглость</th>\n",
       "      <th>yagpt_predictions_Согласованность</th>\n",
       "      <th>yagpt3_predictions</th>\n",
       "      <th>yagpt3_predictions_Актуальность</th>\n",
       "      <th>yagpt3_predictions_Последовательность</th>\n",
       "      <th>yagpt3_predictions_Беглость</th>\n",
       "      <th>yagpt3_predictions_Согласованность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>Активированный в смартфоне Bluetooth может пре...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Постоянно включенный Bluetooth на смартфоне гр...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Постоянно включенный Bluetooth на смартфоне ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Доцент кафедры информатики РЭУ им. Плеханова А...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>Члена президиума оппозиционного Координационно...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Член президиума координационного совета оппози...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Член президиума координационного совета оппо...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Мария Колесникова, член президиума координацио...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аналитики Deutsche Bank обнародовали исследова...</td>\n",
       "      <td>В истории человечества наступает эпоха беспоря...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>В 2020 году в мире наступит новая эпоха беспор...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Аналитики Deutsche Bank предсказали наступле...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Аналитики Deutsche Bank предсказали наступлени...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>Масштабный проект изменений в ПДД подготовили ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработала масшт...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- ГИБДД и Минтранс разработали масштабный прое...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ГИБДД совместно с Минтрансом разработали масшт...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вечером 22 сентября на конференции Battery Day...</td>\n",
       "      <td>Миллиардер Илон Маск пообещал представить бюдж...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>На конференции Battery Day глава Tesla Илон Ма...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>- Глава Tesla Илон Маск анонсировал вывод на р...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>На конференции Battery Day Илон Маск объявил о...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  Аналитики Deutsche Bank обнародовали исследова...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  Вечером 22 сентября на конференции Battery Day...   \n",
       "\n",
       "                                             summary  summary_Актуальность  \\\n",
       "0  Активированный в смартфоне Bluetooth может пре...                   5.0   \n",
       "1  Члена президиума оппозиционного Координационно...                   5.0   \n",
       "2  В истории человечества наступает эпоха беспоря...                   5.0   \n",
       "3  Масштабный проект изменений в ПДД подготовили ...                   4.0   \n",
       "4  Миллиардер Илон Маск пообещал представить бюдж...                   4.0   \n",
       "\n",
       "   summary_Последовательность  summary_Беглость  summary_Согласованность  \\\n",
       "0                         5.0               5.0                      5.0   \n",
       "1                         5.0               5.0                      5.0   \n",
       "2                         5.0               5.0                      5.0   \n",
       "3                         5.0               5.0                      5.0   \n",
       "4                         4.0               5.0                      4.0   \n",
       "\n",
       "                                   mbart_predictions  \\\n",
       "0  Постоянно включенный Bluetooth на смартфоне гр...   \n",
       "1  Член президиума координационного совета оппози...   \n",
       "2  В 2020 году в мире наступит новая эпоха беспор...   \n",
       "3  ГИБДД совместно с Минтрансом разработала масшт...   \n",
       "4  На конференции Battery Day глава Tesla Илон Ма...   \n",
       "\n",
       "   mbart_predictions_Актуальность  mbart_predictions_Последовательность  \\\n",
       "0                             4.0                                   4.0   \n",
       "1                             4.0                                   4.0   \n",
       "2                             5.0                                   5.0   \n",
       "3                             5.0                                   5.0   \n",
       "4                             5.0                                   5.0   \n",
       "\n",
       "   mbart_predictions_Беглость  ...  \\\n",
       "0                         5.0  ...   \n",
       "1                         5.0  ...   \n",
       "2                         5.0  ...   \n",
       "3                         4.0  ...   \n",
       "4                         5.0  ...   \n",
       "\n",
       "                                   yagpt_predictions  \\\n",
       "0  - Постоянно включенный Bluetooth на смартфоне ...   \n",
       "1  - Член президиума координационного совета оппо...   \n",
       "2  - Аналитики Deutsche Bank предсказали наступле...   \n",
       "3  - ГИБДД и Минтранс разработали масштабный прое...   \n",
       "4  - Глава Tesla Илон Маск анонсировал вывод на р...   \n",
       "\n",
       "  yagpt_predictions_Актуальность  yagpt_predictions_Последовательность  \\\n",
       "0                            4.0                                   4.0   \n",
       "1                            3.0                                   5.0   \n",
       "2                            2.0                                   5.0   \n",
       "3                            3.0                                   4.0   \n",
       "4                            2.0                                   5.0   \n",
       "\n",
       "   yagpt_predictions_Беглость  yagpt_predictions_Согласованность  \\\n",
       "0                         4.0                                4.0   \n",
       "1                         5.0                                5.0   \n",
       "2                         5.0                                4.0   \n",
       "3                         4.0                                4.0   \n",
       "4                         5.0                                4.0   \n",
       "\n",
       "                                  yagpt3_predictions  \\\n",
       "0  Доцент кафедры информатики РЭУ им. Плеханова А...   \n",
       "1  Мария Колесникова, член президиума координацио...   \n",
       "2  Аналитики Deutsche Bank предсказали наступлени...   \n",
       "3  ГИБДД совместно с Минтрансом разработали масшт...   \n",
       "4  На конференции Battery Day Илон Маск объявил о...   \n",
       "\n",
       "  yagpt3_predictions_Актуальность  yagpt3_predictions_Последовательность  \\\n",
       "0                             4.0                                    4.0   \n",
       "1                             3.0                                    3.0   \n",
       "2                             4.0                                    5.0   \n",
       "3                             3.0                                    4.0   \n",
       "4                             4.0                                    5.0   \n",
       "\n",
       "   yagpt3_predictions_Беглость  yagpt3_predictions_Согласованность  \n",
       "0                          5.0                                 5.0  \n",
       "1                          5.0                                 5.0  \n",
       "2                          5.0                                 5.0  \n",
       "3                          5.0                                 4.0  \n",
       "4                          5.0                                 5.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc8a8b4-cd4e-4170-8afd-49dc83eac197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median devs:\n",
      "\tBLEU:  0.08804808220346548 0.5697786640154294\n",
      "\tROUGE:  0.09462855215448177 0.6717088031389432\n",
      "\tMETEOR:  0.09814062886468539 0.5356227643657158\n",
      "\tBERTSCORE:  0.0897634963194529 0.4911042995396112\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "human_metrics = human_metrics[:-1]\n",
    "\n",
    "models = {\n",
    "    \"mbart_predictions\",\n",
    "    \"mt5_predictions\",\n",
    "    \"summarunner_predictions\",\n",
    "    \"llama_7b_predictions\",\n",
    "    \"starling_predictions\",\n",
    "    \"yagpt_predictions\",\n",
    "    \"yagpt3_predictions\"\n",
    "}\n",
    "metrics = {\n",
    "    \"bleu\",\n",
    "    \"rouge1\",\n",
    "    \"meteor\",\n",
    "    \"bertscore_f1\"\n",
    "}\n",
    "\n",
    "texts = []\n",
    "summaries = []\n",
    "labels = {k: {\"multi\": [], \"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []} for k in [0.25, 0.5, 0.75]}\n",
    "human_scores = []\n",
    "auto_scores = {\"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []}\n",
    "totals = {\"bleu\": 0, \"bertscore\": 0, \"rouge\": 0, \"meteor\": 0}\n",
    "deviations = {\"bleu\": [], \"bertscore\": [], \"rouge\": [], \"meteor\": []}\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for (mteric_index, metric_row), (expert_index, expert_row)  in zip(metrics_data.iterrows(), expert_data.iterrows()):\n",
    "        # if any([row[f\"{model}_{metric}\"] is None or math.isnan(row[f\"{model}_{metric}\"]) for metric in metrics]) or row[model] is None or type(row[model]) != str:\n",
    "        #     continue\n",
    "        texts.append(metric_row[\"text\"])\n",
    "        summaries.append(metric_row[model])\n",
    "        human_scores.append(np.mean([expert_row[f\"{model}_{metric}\"] for metric in human_metrics]) / 5)\n",
    "        # print(model, human_scores[-1])\n",
    "\n",
    "        auto_scores[\"bleu\"].append(metric_row[f\"{model}_bleu\"])\n",
    "        auto_scores[\"rouge\"].append(metric_row[f\"{model}_rouge1\"])\n",
    "        auto_scores[\"meteor\"].append(metric_row[f\"{model}_meteor\"])\n",
    "        auto_scores[\"bertscore\"].append(metric_row[f\"{model}_bertscore_f1\"])\n",
    "\n",
    "mean_human = np.mean(human_scores)\n",
    "mean_bleu = np.mean(auto_scores[\"bleu\"])\n",
    "mean_rouge = np.mean(auto_scores[\"rouge\"])\n",
    "mean_meteor = np.mean(auto_scores[\"meteor\"])\n",
    "mean_bertscore = np.mean(auto_scores[\"bertscore\"])\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    human_scores[i] -= mean_human\n",
    "    auto_scores[\"bleu\"][i] -= mean_bleu\n",
    "    auto_scores[\"rouge\"][i] -= mean_rouge\n",
    "    auto_scores[\"meteor\"][i] -= mean_meteor\n",
    "    auto_scores[\"bertscore\"][i] -= mean_bertscore\n",
    "\n",
    "    deviations[\"bleu\"].append(abs(auto_scores[\"bleu\"][i] - human_scores[i]))\n",
    "    deviations[\"rouge\"].append(abs(auto_scores[\"rouge\"][i] - human_scores[i]))\n",
    "    deviations[\"meteor\"].append(abs(auto_scores[\"meteor\"][i] - human_scores[i]))\n",
    "    deviations[\"bertscore\"].append(abs(auto_scores[\"bertscore\"][i] - human_scores[i]))\n",
    "\n",
    "print(\"Median devs:\")\n",
    "print(\"\\tBLEU: \", np.median(deviations[\"bleu\"]), np.max(deviations[\"bleu\"]))\n",
    "print(\"\\tROUGE: \", np.median(deviations[\"rouge\"]), np.max(deviations[\"rouge\"]))\n",
    "print(\"\\tMETEOR: \", np.median(deviations[\"meteor\"]), np.max(deviations[\"meteor\"]))\n",
    "print(\"\\tBERTSCORE: \", np.median(deviations[\"bertscore\"]), np.max(deviations[\"bertscore\"]))\n",
    "\n",
    "for k in [0.5]:\n",
    "    for i in range(len(texts)):\n",
    "        abs_bleu_dev = abs(deviations[\"bleu\"][i] - np.quantile(deviations[\"bleu\"], k)) / np.quantile(deviations[\"bleu\"], k) \n",
    "        abs_rouge_dev = abs(deviations[\"rouge\"][i] - np.quantile(deviations[\"rouge\"], k)) / np.quantile(deviations[\"rouge\"], k) \n",
    "        abs_meteor_dev = abs(deviations[\"meteor\"][i] - np.quantile(deviations[\"meteor\"], k)) / np.quantile(deviations[\"meteor\"], k) \n",
    "        abs_bertscore_dev = abs(deviations[\"bertscore\"][i] - np.quantile(deviations[\"bertscore\"], k)) / np.quantile(deviations[\"bertscore\"], k) \n",
    "    \n",
    "        argm = np.argmin([abs_bleu_dev, abs_rouge_dev, abs_meteor_dev, abs_bertscore_dev])\n",
    "        # dta = [0.0] * 4\n",
    "        # dta[argm] = 1\n",
    "        labels[k][\"multi\"].append(argm)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e17c9-d721-4a3a-beb6-a7b6c719a16e",
   "metadata": {},
   "source": [
    "## Dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6738b67a-06f0-4c5a-8907-e5a68b49dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def get_dataset(tokenizer, metric_name, k):\n",
    "    texts_len = len(texts)\n",
    "    train = int(texts_len * 0.9)\n",
    "    test_val = int(texts_len * 0.1)\n",
    "    max_length = 512\n",
    "    return {\n",
    "        \"train\": MetricsCorrelationDataset(texts=texts[0:train], summaries=summaries[0:train], labels=labels[k][metric_name][0:train], tokenizer=tokenizer, max_length=max_length),\n",
    "        \"test\": MetricsCorrelationDataset(texts=texts[train:texts_len], summaries=summaries[train:texts_len], labels=labels[k][metric_name][train:texts_len], tokenizer=tokenizer, max_length=max_length),\n",
    "        #\"val\": MetricsCorrelationDataset(texts=texts[train + test_val:train + 2 * test_val], summaries=summaries[train + test_val:train + 2 * test_val], labels=labels[metric_name][train + test_val:train + 2 * test_val], tokenizer=tokenizer, max_length=max_length)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89d99e-da37-42b1-b1a2-9ccea375c611",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e18cb1-e9b9-449b-b1c3-dd6f6ff9aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251aacde-38a7-433a-b96f-b0b59f2252bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"automatic_predictor\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68f9ac-926f-4bfc-b55c-71f676022505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4edaf1-e413-4341-9b8a-5150720015a3",
   "metadata": {},
   "source": [
    "## Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a55f994e-0ac1-462d-bf35-4f46b6e6b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probabilities = np.exp(predictions) / np.sum(np.exp(predictions), axis=-1, keepdims=True)\n",
    "    predictions = torch.tensor([float(round(x)) for x in predictions.flatten()])\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
    "    p = precision_score(labels, predictions, average=\"macro\")\n",
    "    r = recall_score(labels, predictions, average=\"macro\")\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f1, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b43b2514-8989-42ee-b593-0a39a47b1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptEncoderConfig,\n",
    ")\n",
    "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=30, encoder_hidden_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a89fd85-fae7-461a-937f-41b3663a5fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,672,705 || all params: 357,033,474 || trainable%: 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skatori/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m rouge_dataset \u001b[38;5;241m=\u001b[39m get_dataset(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/accelerator.py:2125\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2125\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruRoberta-large\", num_labels=1)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "tokenizer.model_max_length=482\n",
    "\n",
    "rouge_dataset = get_dataset(tokenizer, \"multi\", k=0.5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=rouge_dataset[\"train\"],\n",
    "    eval_dataset=rouge_dataset[\"test\"],\n",
    "    tokenizer=rouge_dataset[\"train\"].tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9151d1-5cab-4753-8530-10a0ea01b1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d41dc5-8e47-471b-86ec-848ed84b184f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
